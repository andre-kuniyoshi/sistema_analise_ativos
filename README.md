# Sistema de An√°lise de Ativos Financeiros e Envio de Relat√≥rios

- [Installation](#installation)
- [Usage](#usage)
- [Dataset](#dataset)
- [Config](#config)
- [Contributing](#contributing)

<h2 id="installation">‚ö° Installation</h2>

1. Clone the repository:

```bash
git remote add origin https://github.com/setxpro/sistema_analise_ativos.git
```
2. Install dependencies with Maven

```bash 
    pip install -r requirements.txt
```

---

<h2 id="usage">üöÄ Usage</h2>



## Scripts Python

1. get_dataset.py:
- Importa√ß√£o do yfinance: Coleta dados financeiros do Yahoo Finance.
- Defini√ß√£o dos Ativos: √çndice IBOVESPA (^BVSP), S&P 500 (^GSPC) e taxa USD/BRL (BRL=X).
- Coleta e Tratamento dos Dados: Baixa os dados dos √∫ltimos 6 meses, remove valores faltantes e salva em CSV.

2. main.py:
- Inicializa√ß√£o do Spark: Leitura e manipula√ß√£o de grandes conjuntos de dados.
- C√°lculo dos Retornos Di√°rios: Calcula o retorno di√°rio dos ativos.
- Plotagem de Gr√°ficos: Gera gr√°ficos dos retornos dos ativos.
- C√°lculo dos √öltimos Retornos: Calcula o √∫ltimo retorno di√°rio de cada ativo.

4. sent_email.py:
- Configura√ß√£o do Servidor SMTP: Define o servidor SMTP do Gmail para o envio de e-mails.
- Corpo do E-mail: Inclui um relat√≥rio com os retornos di√°rios e anexos dos gr√°ficos.
- Anexar Arquivos e Enviar E-mail: Anexa os gr√°ficos e envia o e-mail com os dados.


<h2 id="dataset">üóÑÔ∏è Dataset</h2>
O dataset utilizado no projeto cont√©m dados de mercado para os seguintes ativos:

IBOVESPA
S&P 500
USD/BRL
Os dados s√£o coletados diretamente do Yahoo Finance e armazenados em um arquivo CSV (dataset/market_data.csv).

<h2 id="config">üõ†Ô∏è Config</h2>
## Configura√ß√£o do Ambiente
1. Arquivo .env:
- USER_EMAIL: E-mail do remetente.
- PASSWORD_EMAIL: Senha do e-mail do remetente.

## Explica√ß√£o Detalhada
- main.py:
  - Spark Session: Inicializa uma sess√£o do Spark para manipular grandes conjuntos de dados.
  - Leitura e Limpeza de Dados: L√™ o CSV, remove valores nulos e calcula retornos di√°rios.
  - Convers√£o e Plotagem: Converte para pandas e gera gr√°ficos com estilo cyberpunk.
- get_dataset.py:
  - Importa√ß√£o e Defini√ß√£o: Usa yfinance para obter dados financeiros.
  - Tratamento e Armazenamento: Processa e salva os dados em um CSV.
- sent_email.py:
  - Configura√ß√£o e Envio: Define o servidor SMTP e configura o e-mail para envio com anexos.


## Estrutura do docker-compose.yml

- <h4>Spark Master</h4>```spark-master```
  - Imagem: Utiliza a imagem ````bitnami/spark:latest```` para o Spark master.
  - Vari√°veis de ambiente: Define o modo do Spark como master.
  - Portas: Exp√µe as portas 8080 e 7077.
  - Redes: Conecta-se √† rede ```spark-network```.
- <h4>Spark Worker</h4> ```spark-worker```
  - Imagem: Tamb√©m utiliza a imagem bitnami/spark:latest para o Spark worker.
  - Vari√°veis de ambiente: Define o modo do Spark como worker e especifica a URL do Spark master.
  - Depend√™ncias: Garante que o spark-master esteja ativo antes de iniciar.
  - Redes: Conecta-se √† rede spark-network.
- <h4>Jupyter Notebook</h4> ```jupyter``` 
  - Imagem: jupyter/pyspark-notebook
  - Fun√ß√£o: Fornece um ambiente Jupyter para an√°lises e processamento com PySpark.
  - Portas: Exp√µe 8888 (interface do Jupyter Notebook).
  - Volumes: Mapeia o diret√≥rio local ./notebooks para o diret√≥rio de trabalho do Jupyter.
  - Depend√™ncias: Garante que spark-master e spark-worker estejam ativos.
  - Rede: Conecta-se √† spark-network.
  - Comando: Inicia o Jupyter sem um token de autentica√ß√£o.
- <h4>Elasticsearch</h4> ```elasticsearch```
  - Imagem: docker.elastic.co/elasticsearch/elasticsearch:8.10.2
  - Fun√ß√£o: Armazenamento e pesquisa de dados.
  - Portas: Exp√µe 9200 (interface REST).
  - Volumes: Utiliza o volume elasticsearch_data para persist√™ncia.
  - Rede: Conecta-se √† spark-network.
- <h4>Kibana</h4> ```kibana```
  - Imagem: docker.elastic.co/kibana/kibana:8.10.2
  - Fun√ß√£o: Interface de visualiza√ß√£o para dados no Elasticsearch.
  - Portas: Exp√µe 5601 (interface do Kibana).
  - Depend√™ncias: Garante que o elasticsearch esteja ativo.
  - Rede: Conecta-se √† spark-network.
- <h4>Hadoop NameNode</h4> ```namenode```
  - Imagem: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
  - Fun√ß√£o: Gerencia o sistema de arquivos distribu√≠do Hadoop (HDFS).
  - Portas: Exp√µe 50070 (interface web) e 8020 (RPC do Namenode).
  - Volumes: Utiliza o volume namenode-data para persist√™ncia.
  - Rede: Conecta-se √† spark-network.
  - Comando: Formata o HDFS e inicia o Namenode.

- <h4>Hadoop DataNode</h4> ```datanode```
  - Imagem: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
  - Fun√ß√£o: Armazena blocos de dados no HDFS.
  - Vari√°veis: Configura a conex√£o com o Namenode.
  - Depend√™ncias: Garante que o namenode esteja ativo.
  - Portas: Exp√µe 50075

- Volumes: Utiliza o volume datanode-data para persist√™ncia.
- Rede: Conecta-se √† spark-network.
- Comando: Inicia o DataNode.


## Contributing

Contributions are welcome! If you find any issues or have suggestions for improvements, please open an issue or submit a pull request to the repository.

When contributing to this project, please follow the existing code style, [commit conventions](https://github.com/iuricode/padroes-de-commits), and submit your changes in a separate branch.